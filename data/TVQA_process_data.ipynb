{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from moviepy.editor import VideoFileClip\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_json(content, save_path):\n",
    "    with open(save_path, 'w') as f:\n",
    "        f.write(json.dumps(content))\n",
    "def load_jsonl(filename):\n",
    "    with open(filename, \"r\") as f:\n",
    "        return [json.loads(l.strip(\"\\n\")) for l in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input json\n",
    "#set medical video download folder\n",
    "tvqa_folder = \"/home/hlpark/shared/TVQA/video/video_files/\"\n",
    "if not os.path.exists(tvqa_folder):\n",
    "    os.makedirs(tvqa_folder)\n",
    "\n",
    "eval_folder = \"/home/hlpark/REDUCE/REDUCE_benchmarks/HiREST/data/evaluation/tvqa\"\n",
    "if not os.path.exists(eval_folder):\n",
    "    os.makedirs(eval_folder)\n",
    "\n",
    "vid_json_folder = \"/home/hlpark/REDUCE/REDUCE_benchmarks/HiREST/data/splits/tvqa\"\n",
    "if not os.path.exists(vid_json_folder):\n",
    "    os.makedirs(vid_json_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#video duration json file\n",
    "vid_duration_json = \"/home/hlpark/REDUCE/REDUCE_benchmarks/HiREST/data/splits/tvqa/video_duration.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read all video duration\n",
    "if not os.path.exists(vid_duration_json):\n",
    "    video_duration_dict = {}\n",
    "    for root, dir, files in os.walk(os.path.join(tvqa_folder)):\n",
    "        for f in tqdm(files):\n",
    "            video_path = os.path.join(tvqa_folder, f)\n",
    "            if video_path.endswith(\".mp4\"):\n",
    "                video = VideoFileClip(video_path)\n",
    "            else:\n",
    "                video = VideoFileClip(video_path + \".mp4\")\n",
    "            v_duration = video.duration\n",
    "            video_duration_dict[f] = v_duration\n",
    "    save_json(video_duration_dict, vid_duration_json)\n",
    "else:\n",
    "    video_duration_dict = load_jsonl(vid_duration_json)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '/home/hlpark/shared/TVQA/tvqa_qa_release/tvqa_train.jsonl'\n",
    "val_path = '/home/hlpark/shared/TVQA/tvqa_qa_release/tvqa_val.jsonl'\n",
    "test_path = '/home/hlpark/shared/TVQA/tvqa_qa_release/tvqa_test_public.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = load_jsonl(train_path)\n",
    "val = load_jsonl(val_path)\n",
    "test = load_jsonl(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7623\n"
     ]
    }
   ],
   "source": [
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_file_root_path = \"/home/hlpark/shared/TVQA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train = {}\n",
    "new_val = {}\n",
    "new_test = {}\n",
    "video_names = {}\n",
    "vid_dict_train, vid_dict_val, vid_dict_test = {}, {}, {}\n",
    "unav_train_query_cnt, unav_val_query_cnt, unav_test_query_cnt = 0, 0, 0\n",
    "with open(os.path.join(txt_file_root_path, \"tvqa_train_queries.txt\"), \"w\") as f:\n",
    "    for i, qa in enumerate(train):\n",
    "        qa_dict = {}\n",
    "        video_id = qa['vid_name'] + \".mp4\"\n",
    "        qa_dict[video_id] = {}\n",
    "        qa_dict[video_id]['relevant'] = True\n",
    "        qa_dict[video_id]['clip'] = True\n",
    "        qa_dict[video_id]['bounds'] = [qa['ts'].split('-')[0], qa['ts'].split('-')[1]]\n",
    "        qa_dict[video_id]['steps'] = []\n",
    "        qa_dict['qid'] = qa['qid']\n",
    "        qa_dict['answer'] = qa['a' + str(qa['answer_idx'])]\n",
    "        \n",
    "        qa_dict[video_id]['v_duration'] = video_duration_dict[video_id]\n",
    "        new_train[qa['q']] = qa_dict\n",
    "        f.writelines(qa['q'] + \"\\n\")\n",
    "with open(os.path.join(txt_file_root_path, \"tvqa_test_queries.txt\"), \"w\") as f:\n",
    "    for i, qa in enumerate(test):\n",
    "        qa_dict = {}\n",
    "        video_id = qa['vid_name'] + \".mp4\"\n",
    "        qa_dict[video_id] = {}\n",
    "        qa_dict[video_id]['relevant'] = True\n",
    "        qa_dict[video_id]['clip'] = True\n",
    "        qa_dict[video_id]['bounds'] = [qa['ts'].split('-')[0], qa['ts'].split('-')[1]]\n",
    "        qa_dict[video_id]['steps'] = []\n",
    "        qa_dict['qid'] = qa['qid']\n",
    "        #qa_dict['answer'] = qa['a' + str(qa['answer_idx'])]\n",
    "        qa_dict[video_id]['v_duration'] = video_duration_dict[video_id]\n",
    "        new_test[qa['q']] = qa_dict\n",
    "        f.writelines(qa['q'] + \"\\n\")\n",
    "with open(os.path.join(txt_file_root_path, \"tvqa_val_queries.txt\"), \"w\") as f:\n",
    "    for i, qa in enumerate(val):\n",
    "        qa_dict = {}\n",
    "        video_id = qa['vid_name'] + \".mp4\"\n",
    "        qa_dict[video_id] = {}\n",
    "        qa_dict[video_id]['relevant'] = True\n",
    "        qa_dict[video_id]['clip'] = True\n",
    "        qa_dict[video_id]['bounds'] = [qa['ts'].split('-')[0], qa['ts'].split('-')[1]]\n",
    "        qa_dict[video_id]['steps'] = []\n",
    "        qa_dict['qid'] = qa['qid']\n",
    "        qa_dict['answer'] = qa['a' + str(qa['answer_idx'])]\n",
    "        qa_dict[video_id]['v_duration'] = video_duration_dict[video_id]\n",
    "        new_val[qa['q']] = qa_dict\n",
    "        f.writelines(qa['q'] + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_json(new_val, f'{vid_json_folder}/all_data_val.json')\n",
    "save_json(new_test, f'{vid_json_folder}/all_data_test.json')\n",
    "save_json(new_train, f'{vid_json_folder}/all_data_train.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "weak_label_path = \"/home/hlpark/REDUCE/REDUCE_benchmarks/HiREST/data/splits/tvqa/five_labeled_pred_med_train_from_gt_vid_dict.json\"\n",
    "weak_label = json.load(open(weak_label_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17435\n",
      "122039\n"
     ]
    }
   ],
   "source": [
    "print(len(weak_label))\n",
    "print(len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "122039it [00:01, 100198.33it/s]\n"
     ]
    }
   ],
   "source": [
    "new_train_med = {}\n",
    "new_train_nonmed = {}\n",
    "new_train_both = {}\n",
    "for i, qa in tqdm(enumerate(train)):\n",
    "    qa_dict = {}\n",
    "    video_id = qa['vid_name'] + \".mp4\"\n",
    "    qa_dict[video_id] = {}\n",
    "    qa_dict[video_id]['relevant'] = True\n",
    "    qa_dict[video_id]['clip'] = True\n",
    "    qa_dict[video_id]['v_duration'] = video_duration_dict[video_id]\n",
    "    qa_dict[video_id]['bounds'] = [qa['ts'].split('-')[0], qa['ts'].split('-')[1]]\n",
    "    qa_dict[video_id]['steps'] = []\n",
    "    qa_dict['qid'] = qa['qid']\n",
    "    \n",
    "    if qa['vid_name'] in weak_label:\n",
    "        for idx, q in enumerate(weak_label[qa['vid_name']]):\n",
    "            if qa['q'] not in q:\n",
    "                continue\n",
    "            if q[qa['q']] == \"med\":\n",
    "                new_train_med[qa['q']] = qa_dict\n",
    "            elif q[qa['q']] == \"nonmed\":\n",
    "                new_train_nonmed[qa['q']] = qa_dict\n",
    "            new_train_both[qa['q']] = qa_dict\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_json(new_train_med, f'{vid_json_folder}/visual_medical_train.json')\n",
    "save_json(new_train_nonmed, f'{vid_json_folder}/visual_nonmedical_train.json')\n",
    "save_json(new_train_both, f'{vid_json_folder}/postprocessed_full_train.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hirest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
