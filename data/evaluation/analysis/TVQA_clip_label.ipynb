{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import clip\n",
    "from PIL import Image\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame_number(filename):\n",
    "    # This extracts numbers from a filename like 'frame_00001.jpg'\n",
    "    return int(filename.replace('frame_', '').replace('.jpg', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_json(content, save_path):\n",
    "    with open(save_path, 'w') as f:\n",
    "        f.write(json.dumps(content))\n",
    "def load_jsonl(filename):\n",
    "    with open(filename, \"r\") as f:\n",
    "        return [json.loads(l.strip(\"\\n\")) for l in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_from_full = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTAMP ERROR in original json s08e05_seg01_clip_01 with video length 82.67: 67.88-85.38\n",
      "TIMESTAMP ERROR in original json s07e17_seg01_clip_00 with video length 91.67: 27.74-94.02\n",
      "TIMESTAMP ERROR in original json met_s06e13_seg02_clip_18 with video length 73.0: 1.13-113.34\n",
      "TIMESTAMP ERROR in original json s05e12_seg01_clip_01 with video length 80.67: 75.46-81.14\n",
      "TIMESTAMP ERROR in original json s07e17_seg01_clip_00 with video length 91.67: 6.58-94.02\n",
      "TIMESTAMP ERROR in original json met_s03e19_seg02_clip_18 with video length 49.0: 12.88-80.5\n",
      "TIMESTAMP ERROR in original json met_s06e15_seg02_clip_18 with video length 73.0: 0-103.17\n",
      "TIMESTAMP ERROR in original json met_s06e15_seg02_clip_18 with video length 73.0: 17.02-103.17\n",
      "TIMESTAMP ERROR in original json met_s02e19_seg01_clip_01 with video length 56.0: 47.9-57.02\n",
      "TIMESTAMP ERROR in original json s03e12_seg01_clip_00 with video length 122.67: 97.37-124.04\n",
      "TIMESTAMP ERROR in original json s10e01_seg01_clip_01 with video length 71.0: 1.1-73.09\n",
      "TIMESTAMP ERROR in original json s01e08_seg01_clip_03 with video length 69.0: 6.67-70.17\n",
      "TIMESTAMP ERROR in original json s10e01_seg01_clip_01 with video length 71.0: 11.69-73.09\n",
      "TIMESTAMP ERROR in original json met_s06e15_seg02_clip_18 with video length 73.0: 47.97-103.17\n",
      "TIMESTAMP ERROR in original json met_s02e03_seg02_clip_19 with video length 33.67: 28.25-34.28\n",
      "TIMESTAMP ERROR in original json s05e08_seg01_clip_01 with video length 92.67: 44.12-98.04\n",
      "TIMESTAMP ERROR in original json met_s05e01_seg01_clip_02 with video length 79.67: 71.43-80.72\n",
      "TIMESTAMP ERROR in original json met_s03e13_seg02_clip_17 with video length 119.67: 78.26-123.73\n",
      "TIMESTAMP ERROR in original json s02e20_seg01_clip_02 with video length 81.67: 66.45-82.04\n",
      "TIMESTAMP ERROR in original json s05e19_seg01_clip_01 with video length 92.67: 88.85-95.03\n",
      "TIMESTAMP ERROR in original json s08e21_seg01_clip_01 with video length 72.0: 16.81-73.1\n",
      "TIMESTAMP ERROR in original json met_s04e02_seg02_clip_17 with video length 64.0: 49.72-92.07\n",
      "TIMESTAMP ERROR in original json met_s06e15_seg02_clip_18 with video length 73.0: 69.64-103.17\n",
      "TIMESTAMP ERROR in original json s07e17_seg01_clip_00 with video length 91.67: 6.58-94.02\n",
      "TIMESTAMP ERROR in original json s02e12_seg01_clip_01 with video length 65.0: 58.76-66.02\n",
      "TIMESTAMP ERROR in original json met_s06e01_seg02_clip_16 with video length 111.67: 136.83-146.34\n",
      "TIMESTAMP ERROR in original json s05e19_seg01_clip_01 with video length 92.67: 23.76-95.03\n",
      "TIMESTAMP ERROR in original json s07e16_seg01_clip_01 with video length 40.0: 36.14-43.02\n",
      "TIMESTAMP ERROR in original json s10e03_seg02_clip_17 with video length 77.67: 63.9-106.5\n",
      "TIMESTAMP ERROR in original json s07e11_seg01_clip_00 with video length 87.67: 77.87-90.02\n",
      "TIMESTAMP ERROR in original json met_s03e19_seg02_clip_18 with video length 49.0: 22.14-80.5\n",
      "TIMESTAMP ERROR in original json s08e05_seg01_clip_01 with video length 82.67: 5.55-85.38\n",
      "TIMESTAMP ERROR in original json met_s06e15_seg02_clip_18 with video length 73.0: 66.55-103.17\n",
      "TIMESTAMP ERROR in original json s04e08_seg01_clip_01 with video length 67.0: 56.74-69.2\n",
      "TIMESTAMP ERROR in original json met_s03e19_seg02_clip_18 with video length 49.0: 0-62.79\n",
      "TIMESTAMP ERROR in original json met_s03e19_seg02_clip_18 with video length 49.0: 18.52-80.5\n",
      "TIMESTAMP ERROR in original json s01e08_seg01_clip_03 with video length 69.0: 39.64-70.17\n",
      "TIMESTAMP ERROR in original json s10e03_seg02_clip_17 with video length 77.67: 72.95-106.5\n",
      "TIMESTAMP ERROR in original json met_s03e19_seg02_clip_18 with video length 49.0: 33.81-80.5\n",
      "TIMESTAMP ERROR in original json s10e01_seg01_clip_01 with video length 71.0: 39.47-73.09\n",
      "TIMESTAMP ERROR in original json met_s06e01_seg02_clip_16 with video length 111.67: 92.93-146.34\n",
      "TIMESTAMP ERROR in original json met_s04e02_seg02_clip_17 with video length 64.0: 70.89-92.07\n",
      "TIMESTAMP ERROR in original json met_s06e13_seg02_clip_18 with video length 73.0: 68.01-77.64\n",
      "TIMESTAMP ERROR in original json met_s02e05_seg02_clip_19 with video length 46.0: 0-75.02\n",
      "TIMESTAMP ERROR in original json s05e08_seg01_clip_01 with video length 92.67: 58.82-98.04\n",
      "TIMESTAMP ERROR in original json s02e20_seg01_clip_02 with video length 81.67: 76.71-82.04\n",
      "TIMESTAMP ERROR in original json met_s02e03_seg02_clip_19 with video length 33.67: 24.76-42.53\n",
      "TIMESTAMP ERROR in original json s07e21_seg02_clip_15 with video length 76.67: 63.53-77.01\n",
      "TIMESTAMP ERROR in original json s05e17_seg02_clip_17 with video length 94.67: 3.37-96.28\n",
      "TIMESTAMP ERROR in original json s05e17_seg02_clip_17 with video length 94.67: 55.84-96.28\n",
      "TIMESTAMP ERROR in original json s02e23_seg01_clip_00 with video length 90.67: 75.09-91.02\n",
      "TIMESTAMP ERROR in original json met_s03e16_seg02_clip_15 with video length 75.0: 67.91-76.79\n",
      "TIMESTAMP ERROR in original json s01e14_seg02_clip_16 with video length 63.0: 53.97-64.64\n",
      "TIMESTAMP ERROR in original json s07e03_seg02_clip_17 with video length 47.0: 40.35-48.04\n",
      "TIMESTAMP ERROR in original json s05e17_seg02_clip_17 with video length 94.67: 38.99-96.28\n"
     ]
    }
   ],
   "source": [
    "random.seed(10)\n",
    "if extract_from_full:\n",
    "    file_dict = {'image_path':[], 'video':[] }\n",
    "    \n",
    "    for root, dirs, files in os.walk(\"/home/hlpark/REDUCE/REDUCE_benchmarks/HiREST/data/splits/tvqa/raw_frames\"):\n",
    "        for dir in dirs:\n",
    "            for r, d, file in os.walk(os.path.join(root, dir)):\n",
    "                file_dict['image_path'].append(os.path.join(r, file[random.randrange(len(file))])) \n",
    "                file_dict['video'].append(dir)\n",
    "else:\n",
    "    file_dict = {'image_path':[], 'video':[], 'query':[] }\n",
    "    val_path = '/home/hlpark/shared/TVQA/tvqa_qa_release/tvqa_val.jsonl'\n",
    "    test_path = '/home/hlpark/shared/TVQA/tvqa_qa_release/tvqa_test_public.jsonl'\n",
    "    vid_duration_json = \"/home/hlpark/REDUCE/REDUCE_benchmarks/HiREST/data/splits/tvqa/video_duration.json\"\n",
    "    val = load_jsonl(val_path)\n",
    "    test = load_jsonl(test_path)\n",
    "    vid_duration = load_jsonl(vid_duration_json)\n",
    "    root = \"/home/hlpark/REDUCE/REDUCE_benchmarks/HiREST/data/splits/tvqa/raw_frames\"\n",
    "    for idx, v in enumerate(val):\n",
    "        # for vid_idx, vid in enumerate(file_dict['video']):\n",
    "        #     if file_dict['video'][vid_idx] == v['vid_name'] and file_dict['query'][vid_idx] == v['q']:\n",
    "        #         continue\n",
    "        filenames = os.listdir(os.path.join(root, v['vid_name'] +  \".mp4\"))\n",
    "        sorted_filenames = sorted(filenames, key=get_frame_number)\n",
    "        #print(sorted_filenames)\n",
    "        if math.isnan(float(v['ts'].split('-')[0])) or math.isnan(float(v['ts'].split('-')[1])):\n",
    "            k = random.randint(0, len(filenames) - 1)\n",
    "            # k = len(filenames) // 2\n",
    "        elif int(float(v['ts'].split('-')[1])) > vid_duration[0][v['vid_name'] + \".mp4\"] or int(float(v['ts'].split('-')[0])) > vid_duration[0][v['vid_name'] + \".mp4\"]:\n",
    "            print(f\"TIMESTAMP ERROR in original json {v['vid_name']} with video length {vid_duration[0][v['vid_name'] + '.mp4']}: {v['ts']}\")\n",
    "            k = random.randint(0, len(filenames) - 1)\n",
    "        else:\n",
    "            k = random.randint(int(float(v['ts'].split('-')[0])), int(float(v['ts'].split('-')[1])))\n",
    "            #k = (int(float(v['ts'].split('-')[0])) + int(float(v['ts'].split('-')[1]))) // 2\n",
    "        #print(vid_duration[0][v['vid_name'] + \".mp4\"],v['vid_name'], len(sorted_filenames), k, v['ts'])\n",
    "        file_dict['image_path'].append(os.path.join(root, v['vid_name'] +  '.mp4', sorted_filenames[k]))\n",
    "        file_dict['video'].append(v['vid_name'])\n",
    "        file_dict['query'].append(v['q'])\n",
    "        \n",
    "    for idx, v in enumerate(test):\n",
    "        # for vid_idx, vid in enumerate(file_dict['video']):\n",
    "        #     if file_dict['video'][vid_idx] == v['vid_name'] and file_dict['query'][vid_idx] == v['q']:\n",
    "        #         continue\n",
    "        filenames = os.listdir(os.path.join(root, v['vid_name'] +  \".mp4\"))\n",
    "        sorted_filenames = sorted(filenames, key=get_frame_number)\n",
    "        #print(sorted_filenames)\n",
    "        if math.isnan(float(v['ts'].split('-')[0])) or math.isnan(float(v['ts'].split('-')[1])):\n",
    "            k = random.randint(0, len(filenames) - 1)\n",
    "            #k = len(filenames) // 2\n",
    "        elif int(float(v['ts'].split('-')[1])) > vid_duration[0][v['vid_name'] + \".mp4\"] or int(float(v['ts'].split('-')[0])) > vid_duration[0][v['vid_name'] + \".mp4\"]:\n",
    "            print(f\"TIMESTAMP ERROR in original json {v['vid_name']} with video length {vid_duration[0][v['vid_name'] + '.mp4']}: {v['ts']}\")\n",
    "            k = random.randint(0, len(filenames) - 1)\n",
    "        else:\n",
    "            k = random.randint(int(float(v['ts'].split('-')[0])), int(float(v['ts'].split('-')[1])))\n",
    "            #k = (int(float(v['ts'].split('-')[0])) + int(float(v['ts'].split('-')[1]))) // 2\n",
    "        file_dict['image_path'].append(os.path.join(root, v['vid_name'] +  \".mp4\", sorted_filenames[k]))\n",
    "        file_dict['video'].append(v['vid_name'])\n",
    "        file_dict['query'].append(v['q'])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22876\n"
     ]
    }
   ],
   "source": [
    "print(len(file_dict['video']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame.from_dict(file_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"/home/hlpark/REDUCE/REDUCE_benchmarks/HiREST/data/evaluation/analysis/TVQA\"):\n",
    "    os.makedirs(\"/home/hlpark/REDUCE/REDUCE_benchmarks/HiREST/data/evaluation/analysis/TVQA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This is a hospital', 'This is a office', 'This is a home', 'This is a school', 'This is a outside']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 999/22876 [00:06<02:19, 156.63it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 288.00 MiB (GPU 0; 23.48 GiB total capacity; 2.64 GiB already allocated; 191.06 MiB free; 2.87 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 36\u001b[0m\n\u001b[1;32m     34\u001b[0m image_input \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(np\u001b[38;5;241m.\u001b[39mstack(images))\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 36\u001b[0m     image_features \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_input\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m     37\u001b[0m     image_features \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m image_features\u001b[38;5;241m.\u001b[39mnorm(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     38\u001b[0m     img_feats\u001b[38;5;241m.\u001b[39mappend(image_features\u001b[38;5;241m.\u001b[39mcpu())\n",
      "File \u001b[0;32m~/miniconda3/envs/hirest/lib/python3.8/site-packages/clip/model.py:341\u001b[0m, in \u001b[0;36mCLIP.encode_image\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencode_image\u001b[39m(\u001b[38;5;28mself\u001b[39m, image):\n\u001b[0;32m--> 341\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvisual(\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 288.00 MiB (GPU 0; 23.48 GiB total capacity; 2.64 GiB already allocated; 191.06 MiB free; 2.87 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "## Caption embeddings\n",
    "# texts = ['hospital', 'office', 'home', 'school', 'outside', 'not hospital']        # FIXME fill in classes here (e.g., hospital, not hospital)\n",
    "# name = \"six_labels\"\n",
    "texts = ['hospital', 'office', 'home', 'school', 'outside']        # FIXME fill in classes here (e.g., hospital, not hospital)\n",
    "name = \"five_labels\"\n",
    "# texts = ['hospital', 'not hospital']        # FIXME fill in classes here (e.g., hospital, not hospital)\n",
    "# name = \"two_labels\"\n",
    "\n",
    "if not os.path.exists(f\"./TVQA/txt_probs_{name}.pt\"):\n",
    "    model, preprocess = clip.load(\"ViT-B/32\")\n",
    "    model.cuda().eval()\n",
    "    input_resolution = model.visual.input_resolution\n",
    "    context_length = model.context_length\n",
    "    vocab_size = model.vocab_size\n",
    "    prob_dict = {}\n",
    "    \n",
    "    captions = [\"This is a \" + desc for desc in texts]\n",
    "    print(captions)\n",
    "    text_tokens = clip.tokenize(captions).cuda()\n",
    "    with torch.no_grad():\n",
    "        text_features = model.encode_text(text_tokens).float()\n",
    "        text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "    batch_size = 1000\n",
    "    images, img_feats, txt_probs = [], [], []\n",
    "    for i, x in tqdm(data.iterrows(), total=data.shape[0]):     # FIXME make this iterate over your data\n",
    "\n",
    "        path = x['image_path']        # FIXME replace with the frame from the appropriate video\n",
    "        image = Image.open(path).convert(\"RGB\")\n",
    "        images.append(preprocess(image))\n",
    "        \n",
    "        if ((i + 1) % batch_size == 0) or (i + 1 == data.shape[0]):\n",
    "            ## Image embeddings\n",
    "            image_input = torch.tensor(np.stack(images)).cuda()\n",
    "            with torch.no_grad():\n",
    "                image_features = model.encode_image(image_input).float()\n",
    "                image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "                img_feats.append(image_features.cpu())\n",
    "\n",
    "            ## Caption probabilities\n",
    "            text_probs = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
    "            txt_probs.append(text_probs.cpu())\n",
    "            images = []\n",
    "\n",
    "    img_feats = torch.cat(img_feats, dim=0)\n",
    "    txt_probs = torch.cat(txt_probs, dim=0)\n",
    "    torch.save(img_feats, f'./TVQA/img_feats_{name}.pt')\n",
    "    torch.save(txt_probs, f'./TVQA/txt_probs_{name}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0482, 0.6361, 0.1704, 0.0059, 0.1394],\n",
      "        [0.0764, 0.7330, 0.1302, 0.0088, 0.0517],\n",
      "        [0.0029, 0.4164, 0.5463, 0.0108, 0.0235],\n",
      "        ...,\n",
      "        [0.1730, 0.3055, 0.3500, 0.0617, 0.1098],\n",
      "        [0.1235, 0.5070, 0.0635, 0.0244, 0.2817],\n",
      "        [0.5324, 0.3607, 0.0900, 0.0020, 0.0149]])\n",
      "0\n",
      "3268\n",
      "590\n",
      "image_path    /home/hlpark/REDUCE/REDUCE_benchmarks/HiREST/d...\n",
      "video                                  s08e24_seg02_clip_14.mp4\n",
      "Name: 0, dtype: object\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'query'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/hirest/lib/python3.8/site-packages/pandas/core/indexes/base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/miniconda3/envs/hirest/lib/python3.8/site-packages/pandas/_libs/index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/hirest/lib/python3.8/site-packages/pandas/_libs/index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'query'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 45\u001b[0m\n\u001b[1;32m     42\u001b[0m         img\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mroot\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_classification_images/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_nmm/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m data\u001b[38;5;241m.\u001b[39miloc[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvideo\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJPEG\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 45\u001b[0m     label_dict[data\u001b[38;5;241m.\u001b[39miloc[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvideo\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mappend({\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mquery\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m : \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonmed\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39miloc[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvideo\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m non_med_vid_list:\n\u001b[1;32m     47\u001b[0m         non_med_vid_list\u001b[38;5;241m.\u001b[39mappend(data\u001b[38;5;241m.\u001b[39miloc[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvideo\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/envs/hirest/lib/python3.8/site-packages/pandas/core/series.py:1007\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1004\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m   1006\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1007\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_hashable(key):\n\u001b[1;32m   1010\u001b[0m     \u001b[38;5;66;03m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[1;32m   1011\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1012\u001b[0m         \u001b[38;5;66;03m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/hirest/lib/python3.8/site-packages/pandas/core/series.py:1116\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1115\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1116\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m~/miniconda3/envs/hirest/lib/python3.8/site-packages/pandas/core/indexes/base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'query'"
     ]
    }
   ],
   "source": [
    "# from IPython.display import Image, display\n",
    "from PIL import Image\n",
    "label  = \"five_labels\"\n",
    "probs = torch.load(f\"./TVQA/txt_probs_{label}.pt\")\n",
    "cnt = 0\n",
    "med_vid_list, non_med_vid_list = [], []\n",
    "label_dict = {}\n",
    "print(probs)\n",
    "for p in probs[0]:\n",
    "    if np.argmax(p) == 0 and p > 0.8:\n",
    "        cnt += 1\n",
    "\n",
    "print(cnt)\n",
    "\n",
    "root = \"/home/hlpark/REDUCE/REDUCE_benchmarks/HiREST/data/evaluation/analysis/TVQA\"\n",
    "if not os.path.exists(os.path.join(root, f\"{label}_classification_images/\")):\n",
    "    os.makedirs(os.path.join(root, f\"{label}_classification_images\"))\n",
    "    os.makedirs(os.path.join(root, f\"{label}_classification_images/{label}_mm\"))\n",
    "    os.makedirs(os.path.join(root, f\"{label}_classification_images/{label}_nmm\"))\n",
    "    os.makedirs(os.path.join(root, f\"{label}_classification_images/{label}_mnm\"))\n",
    "    os.makedirs(os.path.join(root, f\"{label}_classification_images/{label}_nmnm\"))\n",
    "max_idx = np.argmax(probs, 1)\n",
    "max_idx = max_idx.tolist()\n",
    "print(len(max_idx))\n",
    "print(max_idx.count(0))\n",
    "medical_tv_class_med, medical_tv_class_nonmed = 0, 0\n",
    "nonmedical_tv_class_med, nonmedical_tv_class_nonmed = 0, 0\n",
    "for i,x in enumerate(max_idx):\n",
    "    img = Image.open(data.iloc[i]['image_path'])\n",
    "    print(data.iloc[i])\n",
    "    if data.iloc[i]['video'] not in label_dict:\n",
    "        label_dict[data.iloc[i]['video']] = []\n",
    "    if x == 0:\n",
    "        label_dict[data.iloc[i]['video']].append({data.iloc[i]['query'] : \"med\"})\n",
    "        if data.iloc[i]['video'] not in med_vid_list:\n",
    "            med_vid_list.append(data.iloc[i]['video'])\n",
    "        if \"house\" in data.iloc[i]['video'] or \"grey\" in data.iloc[i]['video']:\n",
    "            medical_tv_class_med += 1\n",
    "            img.save(f\"{root}/{label}_classification_images/{label}_mm/\" + data.iloc[i]['video'] + \".jpg\", 'JPEG')\n",
    "        else:\n",
    "            nonmedical_tv_class_med += 1\n",
    "            img.save(f\"{root}/{label}_classification_images/{label}_nmm/\" + data.iloc[i]['video'] + \".jpg\", 'JPEG')\n",
    "\n",
    "    else:\n",
    "        label_dict[data.iloc[i]['video']].append({data.iloc[i]['query'] : \"nonmed\"})\n",
    "        if data.iloc[i]['video'] not in non_med_vid_list:\n",
    "            non_med_vid_list.append(data.iloc[i]['video'])\n",
    "        if \"house\" in data.iloc[i]['video'] or \"grey\" in data.iloc[i]['video']:\n",
    "            medical_tv_class_nonmed += 1\n",
    "            img.save(f\"{root}/{label}_classification_images/{label}_mnm/\" + data.iloc[i]['video'] + \".jpg\", 'JPEG')\n",
    "\n",
    "        else:\n",
    "            nonmedical_tv_class_nonmed += 1\n",
    "            img.save(f\"{root}/{label}_classification_images/{label}_nmnm/\" + data.iloc[i]['video'] + \".jpg\", 'JPEG')\n",
    "\n",
    "\n",
    "print(medical_tv_class_med, medical_tv_class_nonmed, nonmedical_tv_class_med, nonmedical_tv_class_nonmed)\n",
    "print(\"medical video numbers: \", len(med_vid_list), \"non-medical video numbers: \", len(non_med_vid_list))\n",
    "#save_json(label_dict, \"/home/hlpark/REDUCE/REDUCE_benchmarks/HiREST/data/splits/medvidqa/five_labeled_pred_med_from_gt_vid_dict.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3268\n",
      "1564\n",
      "565 287 999 1417\n"
     ]
    }
   ],
   "source": [
    "# from IPython.display import Image, display\n",
    "from PIL import Image\n",
    "probs = torch.load(\"./txt_probs_two_labels.pt\")\n",
    "# cnt = 0\n",
    "# for i, x in data.iterrows():\n",
    "#     if probs[i][0] > 0.80:\n",
    "#         #print(x['image_path'], probs[i])\n",
    "#         cnt += 1\n",
    "#         img = Image.open(x['image_path'])\n",
    "#         img.save(\"image_08_two_labels/\" + x['video'] + \".jpg\", 'JPEG')\n",
    "#         # if \"house\" not in x['image_path'] and \"grey\" not in x['image_path']:\n",
    "#         #     display(Image(filename=x['image_path']))\n",
    "#         # display(Image(filename=x['image_path']))\n",
    "    \n",
    "\n",
    "# print(cnt)\n",
    "max_idx = np.argmax(probs, 1)\n",
    "max_idx = max_idx.tolist()\n",
    "print(len(max_idx))\n",
    "print(max_idx.count(0))\n",
    "medical_tv_class_med, medical_tv_class_nonmed = 0, 0\n",
    "nonmedical_tv_class_med, nonmedical_tv_class_nonmed = 0, 0\n",
    "for i,x in enumerate(max_idx):\n",
    "    img = Image.open(data.iloc[i]['image_path'])\n",
    "    if x == 0:\n",
    "        if \"house\" in data.iloc[i]['video'] or \"grey\" in data.iloc[i]['video']:\n",
    "            medical_tv_class_med += 1\n",
    "            img.save(\"two_label_classification_images/two_label_mm/\" + data.iloc[i]['video'] + \".jpg\", 'JPEG')\n",
    "        else:\n",
    "            nonmedical_tv_class_med += 1\n",
    "            img.save(\"two_label_classification_images/two_label_nmm/\" + data.iloc[i]['video'] + \".jpg\", 'JPEG')\n",
    "\n",
    "    else:\n",
    "        if \"house\" in data.iloc[i]['video'] or \"grey\" in data.iloc[i]['video']:\n",
    "            medical_tv_class_nonmed += 1\n",
    "            img.save(\"two_label_classification_images/two_label_mnm/\" + data.iloc[i]['video'] + \".jpg\", 'JPEG')\n",
    "        else:\n",
    "            nonmedical_tv_class_nonmed += 1\n",
    "            img.save(\"two_label_classification_images/two_label_nmnm/\" + data.iloc[i]['video'] + \".jpg\", 'JPEG')\n",
    "\n",
    "print(medical_tv_class_med, medical_tv_class_nonmed, nonmedical_tv_class_med, nonmedical_tv_class_nonmed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "459\n",
      "3268\n",
      "590\n",
      "473 379 117 2299\n"
     ]
    }
   ],
   "source": [
    "# from IPython.display import Image, display\n",
    "from PIL import Image\n",
    "probs = torch.load(\"./txt_probs_five_labels.pt\")\n",
    "five_label_dict = {}\n",
    "cnt = 0\n",
    "for i, x in data.iterrows():\n",
    "    # if np.argmax(probs[i]) == 0 and \"house\" in x['image_path']:\n",
    "    #     print(x['image_path'], probs[i])\n",
    "    if probs[i][0] > 0.50:\n",
    "        #print(x['image_path'], probs[i])\n",
    "        cnt += 1\n",
    "        img = Image.open(x['image_path'])\n",
    "\n",
    "        img.save(\"image_05_five_labels/\" + x['video'] + \".jpg\", 'JPEG')\n",
    "        # if \"house\" not in x['image_path'] and \"grey\" not in x['image_path']:\n",
    "        #     display(Image(filename=x['image_path']))\n",
    "        # display(Image(filename=x['image_path']))\n",
    "print(cnt)\n",
    "max_idx = np.argmax(probs, 1)\n",
    "max_idx = max_idx.tolist()\n",
    "print(len(max_idx))\n",
    "print(max_idx.count(0))\n",
    "medical_tv_class_med, medical_tv_class_nonmed = 0, 0\n",
    "nonmedical_tv_class_med, nonmedical_tv_class_nonmed = 0, 0\n",
    "for i,x in enumerate(max_idx):\n",
    "    img = Image.open(data.iloc[i]['image_path'])\n",
    "    if x == 0:\n",
    "        five_label_dict[data.iloc[i]['video']] = \"med\"\n",
    "        if \"house\" in data.iloc[i]['video'] or \"grey\" in data.iloc[i]['video']:\n",
    "            medical_tv_class_med += 1\n",
    "            img.save(\"five_label_classification_images/five_label_mm/\" + data.iloc[i]['video'] + \".jpg\", 'JPEG')\n",
    "        else:\n",
    "            nonmedical_tv_class_med += 1\n",
    "            img.save(\"five_label_classification_images/five_label_nmm/\" + data.iloc[i]['video'] + \".jpg\", 'JPEG')\n",
    "\n",
    "    else:\n",
    "        five_label_dict[data.iloc[i]['video']] = \"nonmed\"\n",
    "        if \"house\" in data.iloc[i]['video'] or \"grey\" in data.iloc[i]['video']:\n",
    "            medical_tv_class_nonmed += 1\n",
    "            img.save(\"five_label_classification_images/five_label_mnm/\" + data.iloc[i]['video'] + \".jpg\", 'JPEG')\n",
    "\n",
    "        else:\n",
    "            nonmedical_tv_class_nonmed += 1\n",
    "            img.save(\"five_label_classification_images/five_label_nmnm/\" + data.iloc[i]['video'] + \".jpg\", 'JPEG')\n",
    "\n",
    "\n",
    "print(medical_tv_class_med, medical_tv_class_nonmed, nonmedical_tv_class_med, nonmedical_tv_class_nonmed)\n",
    "save_json(five_label_dict, \"/home/hlpark/REDUCE/REDUCE_benchmarks/HiREST/data/splits/tvqa/five_labeled_pred_med_vid_dict.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9595, 0.0175, 0.0130, 0.0028, 0.0071], grad_fn=<SelectBackward0>)\n",
      "tensor([0.4154, 0.5116, 0.0274, 0.0141, 0.0314], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# from IPython.display import Image, display\n",
    "from PIL import Image\n",
    "label  = \"no_batch_five_labels\"\n",
    "#probs = torch.load(f\"./txt_probs_{label}.pt\")\n",
    "cnt = 0\n",
    "label_dict = {}\n",
    "for i, x in data.iterrows():\n",
    "    if \"grey_s01e01_seg02_clip_09\" in x['image_path'] or \"house_s05e16_seg02_clip_02\" in x['image_path']:\n",
    "        print(txt_probs[i])\n",
    "\n",
    "#     # if np.argmax(probs[i]) == 0 and \"house\" in x['image_path']:\n",
    "#     #     print(x['image_path'], probs[i])\n",
    "#     if probs[i][0] > 0.80:\n",
    "#         #print(x['image_path'], probs[i])\n",
    "#         cnt += 1\n",
    "#         img = Image.open(x['image_path'])\n",
    "\n",
    "#         img.save(\"image_08_five_labels/\" + x['video'] + \".jpg\", 'JPEG')\n",
    "#         # if \"house\" not in x['image_path'] and \"grey\" not in x['image_path']:\n",
    "#         #     display(Image(filename=x['image_path']))\n",
    "#         # display(Image(filename=x['image_path']))\n",
    "# print(cnt)\n",
    "root = \"/home/hlpark/REDUCE/REDUCE_benchmarks/HiREST/data/evaluation/analysis\"\n",
    "if not os.path.exists(os.path.join(root, f\"{label}_classification_images/\")):\n",
    "    os.makedirs(os.path.join(root, f\"{label}_classification_images\"))\n",
    "    os.makedirs(os.path.join(root, f\"{label}_classification_images/{label}_mm\"))\n",
    "    os.makedirs(os.path.join(root, f\"{label}_classification_images/{label}_nmm\"))\n",
    "    os.makedirs(os.path.join(root, f\"{label}_classification_images/{label}_mnm\"))\n",
    "    os.makedirs(os.path.join(root, f\"{label}_classification_images/{label}_nmnm\"))\n",
    "max_idx = np.argmax(probs, 1)\n",
    "max_idx = max_idx.tolist()\n",
    "print(len(max_idx))\n",
    "print(max_idx.count(0))\n",
    "medical_tv_class_med, medical_tv_class_nonmed = 0, 0\n",
    "nonmedical_tv_class_med, nonmedical_tv_class_nonmed = 0, 0\n",
    "for i,x in enumerate(max_idx):\n",
    "    img = Image.open(data.iloc[i]['image_path'])\n",
    "    if data.iloc[i]['video'] not in label_dict:\n",
    "        label_dict[data.iloc[i]['video']] = []\n",
    "    if x == 0:\n",
    "        label_dict[data.iloc[i]['video']].append({data.iloc[i]['query'] : \"med\"})\n",
    "        if \"house\" in data.iloc[i]['video'] or \"grey\" in data.iloc[i]['video']:\n",
    "            medical_tv_class_med += 1\n",
    "            img.save(f\"{label}_classification_images/{label}_mm/\" + data.iloc[i]['video'] + \".jpg\", 'JPEG')\n",
    "        else:\n",
    "            nonmedical_tv_class_med += 1\n",
    "            img.save(f\"{label}_classification_images/{label}_nmm/\" + data.iloc[i]['video'] + \".jpg\", 'JPEG')\n",
    "\n",
    "    else:\n",
    "        label_dict[data.iloc[i]['video']].append({data.iloc[i]['query'] : \"nonmed\"})\n",
    "        if \"house\" in data.iloc[i]['video'] or \"grey\" in data.iloc[i]['video']:\n",
    "            medical_tv_class_nonmed += 1\n",
    "            img.save(f\"{label}_classification_images/{label}_mnm/\" + data.iloc[i]['video'] + \".jpg\", 'JPEG')\n",
    "\n",
    "        else:\n",
    "            nonmedical_tv_class_nonmed += 1\n",
    "            img.save(f\"{label}_classification_images/{label}_nmnm/\" + data.iloc[i]['video'] + \".jpg\", 'JPEG')\n",
    "\n",
    "\n",
    "print(medical_tv_class_med, medical_tv_class_nonmed, nonmedical_tv_class_med, nonmedical_tv_class_nonmed)\n",
    "save_json(label_dict, \"/home/hlpark/REDUCE/REDUCE_benchmarks/HiREST/data/splits/tvqa/five_labeled_pred_med_from_gt_vid_dict.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hirest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
